{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a873b970-4e78-4f06-b0d1-81a061ad76f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install typing-extensions\n",
    "# !pip install openai==1.38.0\n",
    "\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1f2da62-de9f-42a7-a8b3-02c4fd37e341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import openai\n",
    "import pprint\n",
    "import random\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "639b397e-66ad-40a0-a58a-df4a9fa088db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filename_data = \"\"\n",
    "data = pd.read_csv(filename_data)[6000::]\n",
    "data = data.drop(columns=\"row_data\")\n",
    "data.display()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba8a2c8-2b13-40c6-b88a-661a7d8252b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filename_annotation_data = \"\"\n",
    "annotation_data = pd.read_json(filename_annotation_data, lines=True)\n",
    "annotation_data.to_json(filename_annotation_data, lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68053e6-8b84-42c9-a989-adef4ba6742c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "annotation_data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34cd3403-6d4a-4499-9554-aad6769a01df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_clean_labels(labels):\n",
    "  \"\"\"\n",
    "  Extracts the clean labels from the exported label structure\n",
    "  \"\"\"\n",
    "  label_processed = []\n",
    "\n",
    "  PROJECT_ID = \"cm1q6nik6098e08xp0d9n176x\"\n",
    "  for i, row in labels.iterrows():\n",
    "    for label in row['projects'][PROJECT_ID]['labels']: \n",
    "        c = label[\"annotations\"]['classifications']\n",
    "        c_df = {}\n",
    "\n",
    "        c_df[\"Global Key\"]  = int(row['data_row']['global_key'])\n",
    "        c_df[\"Labeler\"] = label[\"label_details\"]['created_by']\n",
    "        c_df[\"Description\"] = row['data_row'][\"row_data\"]\n",
    "  \n",
    "        if c != []:\n",
    "          c_df[\"Annotation\"] = label[\"annotations\"]['classifications'][0]['radio_answer']['value']\n",
    "        else:\n",
    "            try:\n",
    "              c_df[\"Annotation\"] = label[\"annotations\"]['objects'][0]['classifications'][0]['checklist_answers'][0]['value']\n",
    "              c_df[\"Annotation_start\"] = str(label[\"annotations\"]['objects'][0]['location']['start'])\n",
    "              c_df[\"Annotation_end\"] = str(label[\"annotations\"]['objects'][0]['location']['end'])\n",
    "              c_df[\"Annotation_token\"] = str(label[\"annotations\"]['objects'][0]['location']['token'])\n",
    "              c_df[\"Category\"] = label[\"annotations\"]['objects'][0]['value']\n",
    "            except:\n",
    "              pass\n",
    "\n",
    "        c_df = pd.DataFrame.from_dict([c_df])\n",
    "        label_processed += [c_df]\n",
    "\n",
    "  processed = pd.concat(label_processed)\n",
    "\n",
    "  return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c767bb7-e73d-4cac-b572-e634a7eb38f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specifies email of the annotator that has to be removed\n",
    "email = \"\"\n",
    "\n",
    "annotation_data_clean = get_clean_labels(annotation_data)\n",
    "annotation_data_clean['INCLUSIEF'] = annotation_data_clean['Annotation'] == \"er_is_hier_geen_sprake_van_niet_inclusief_taalgebruik\"\n",
    "annotation_data_clean = annotation_data_clean[annotation_data_clean['Labeler'] != email]\n",
    "annotation_data_clean = annotation_data_clean[annotation_data_clean['Global Key'] > 6000]\n",
    "annotation_data_clean = annotation_data_clean.sort_values(by='Global Key')\n",
    "annotation_data_clean = annotation_data_clean[annotation_data_clean['Annotation'].notna()]\n",
    "annotation_data_clean.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a33106-20c0-4181-93c9-2cea0202bb93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "annotation_df = annotation_data_clean.groupby(['Global Key']).agg({\n",
    "    'Global Key': 'first',\n",
    "    'INCLUSIEF': 'all',\n",
    "    'Annotation': lambda x: ' | '.join(str(i) for i in x),\n",
    "    'Category' : lambda x: ' | '.join(str(i) for i in x)\n",
    "})\n",
    "annotation_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5bdbc94-d0a5-47c6-b22b-73895d5cee53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in annotation_df['INCLUSIEF']:\n",
    "    if i:\n",
    "        count += 1\n",
    "\n",
    "print(\"Number of non inclusive datarows:\", len(annotation_df) - count)\n",
    "print(\"Dataset length:\",len(annotation_data_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2325ca9-4ea0-4cd8-9006-d74da6928d53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gender = [\n",
    "    {\"\"\"Zij is de hoofdredactrice in het project.\"\"\"},\n",
    "    \n",
    "    {\"\"\"De 47-jarige Sietsma werkt sinds 2017 als onderzoeksjournaliste voor het NOS/NTR-programma Nieuwsuur, en was daarvoor al zeven jaar werkzaam voor RTL Nieuws, ook als journaliste bij de onderzoeksredactie. Eerdere werkervaring deed hij op bij de actualiteitenprogrammaâ€™s Twee Vandaag en Netwerk. \"\"\"},\n",
    "\n",
    "    {\"\"\"De vrouwelijke CEO gaf een speech.\"\"\"},\n",
    "\n",
    "    {\"\"\"Premier Rutte en vicepremier Sigrid Kaag\"\"\"}\n",
    "]\n",
    "\n",
    "seksuele_orientatie = [\n",
    "    {\"\"\"Er wordt vaak neergekeken op mensen met een andere seksualiteit\"\"\"}, \n",
    "                        \n",
    "    {\"\"\"De groep bestaat met name uit homo's\"\"\"}, \n",
    "\n",
    "    {\"\"\"Een panseksueel is iemand die zich aangetrokken voelt tot alle genderidentiteiten.\"\"\"}\n",
    "]\n",
    "\n",
    "etniciteit = [\n",
    "    {\"\"\"Veel blanke mensen vinden het moeilijk om zich bewust te zijn van hun privilege\"\"\"}, \n",
    "\n",
    "    {\"\"\"Dit verhaal zal veel mensen met een andere huidskleur bekend voorkomen.\"\"\"}, \n",
    "\n",
    "    {\"\"\"De cast bestaat met name uit allochtonen\"\"\"}\n",
    "]\n",
    "\n",
    "beperking = [\n",
    "    {\"\"\"Gehandicapte mensen zijn vaak de dupe.\"\"\"}, \n",
    "\n",
    "    {\"\"\"Dit programma is toegankelijk voor doven en slechthorenden\"\"\"}, \n",
    "\n",
    "    {\"\"\"De hoofdpersoon lijdt aan autisme\"\"\"},\n",
    "\n",
    "    {\"\"\"Bas is blind, maar zit toch in de jury\"\"\"}\n",
    "]\n",
    "\n",
    "inclusief = [\n",
    "    {\"\"\"De documentaire vertelt het verhaal van praktisch opgeleide vrouwen.\"\"\"}, \n",
    "    \n",
    "    {\"\"\"Dit programma is toegangelijk voor dove en slechthorende mensen\"\"\"},\n",
    "\n",
    "    {\"\"\"De groep bestaat met name uit homo mannen\"\"\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0449ed-83d2-43b5-ac92-92c5ad5899ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def initialize_openai_api(): \n",
    "  \"\"\"\n",
    "  Initializes the OpenAI api.\n",
    "  \"\"\"\n",
    "  vault, key = \"\", \"\"\n",
    "  endpoint = \"\"\n",
    "  os.environ['OPENAI_API_KEY'] = dbutils.secrets.get(vault, key)\n",
    "  openai.api_type = \"azure\"\n",
    "  openai.azure_endpoint = endpoint\n",
    "  openai.api_version = \"2024-02-01\"\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def get_initial_prompt_general():\n",
    "  \"\"\"\n",
    "  Returns the role and content for the prompt. The prompts exists of multiple different examples.\n",
    "  \"\"\"\n",
    "  gender1 = gender[random.randint(0, len(gender) - 1)]\n",
    "  seksuele_orientatie1 = seksuele_orientatie[random.randint(0, len(seksuele_orientatie)-1)]\n",
    "  etniciteit1 = etniciteit[random.randint(0, len(etniciteit)-1)]\n",
    "  beperiking1 = beperking[random.randint(0, len(beperking) - 1)]\n",
    "  inclusief1 = inclusief[random.randint(0, len(inclusief) - 1)]\n",
    "\n",
    "  initial_prompt = f\"\"\"\n",
    "    Je bent een systeem dat gespecializeerd is in het detecteren van niet-inclusief taalgebruik in artikelen van RTL. Je doel is om te detecteren of er sprake is van niet-inclusief taalgebruik. Dit zijn criteria voor niet-inclusief taalgebruik: \n",
    "    \n",
    "1. Gender\n",
    "- Vrouwelijke vorm van beroepsnamen (Bijv. hoofdredactrice, voetbalsters)\n",
    "- Genderspecifieke beroepsnamen. (Bijv. politiemannen)\n",
    "- Onnodige bijvoegelijke naamwoorden (Bijv. de vrouwelijke CEO)\n",
    "- Inconsistente achternamen (Bijv. Sigrid Kaag met achternaam en Rutte zonder)\n",
    "- Onjuiste voornaamwoorden (Als gender bekend is, gebruik de juiste voornaamwoorden zij/haar, hij/hem, die/diens etc.)\n",
    "- Stigmatiseren zoals gebruik van \"mannen en vrouwen\" ipv mensen (Bijv. meisje ipv vrouw, 300 man ipv 300 mensen)\n",
    "- Incorrect gebruik van terminologie (Bijv. een transman ipv trans man, een non-binair ipv non-binair persoon)\n",
    "\n",
    "2. Seksuele orientatie\n",
    "- Othering (Bijv. mensen met een andere seksuele orientatie ipv lhbti-personen)\n",
    "- Seksualiteit als bijvoegelijk naamwoord (Bijv. homo's ipv homo mannen)\n",
    "- Stigmatiseren (Bijv. gebruik van woorden zoals homo's, flikkers etc.)\n",
    "- Incorrect gebruik van terminologie (Bijv. een homo ipv een homo man, een panseksueel ipv pansexuele mensen)\n",
    "\n",
    "3. Etniciteit & culturele achtergrond\n",
    "- Verkeerd gebruik van zwart en wit (Bijv. blanke mensen ipv zwarte en witte mensen/mensen van kleur)\n",
    "- Onnodig gebruik van etniciteit (alleen als het relevant is voor de context)\n",
    "- Othering (Bijv. een andere huidskleur)\n",
    "- Etniciteit als bijvoegelijk naamwoord (Bijv. zwarten ipv zwarte mensen)\n",
    "- n-woord (dit woord mag alleen gebruikt worden in historiche context wanneer uitleg en duiding mogelijk is)\n",
    "- Incorrect gebruik van terminologie (Bijv. gebruik van allochtonen of niet-witte mensen) \n",
    "\n",
    "4. Fysieke/mentale beperking\n",
    "- Gebruik van minder valide/invalide/handicap ipv mensen met een beperking\n",
    "- Onnodige bijvoegelijke naamwoorden (Bijv. doven en slechthorenden ipv dove en slechthorende mensen)\n",
    "- Gebruik van \"lijden aan\" (Bijv. \"lijdt aan autisme\" ipv \"heeft autisme\")\n",
    "- Gebruik van constructies waar een beperking een uitzondering is (Bijv. hij is blind, maar zit toch in de jury)\n",
    "- Onnodige bijvoegelijke naamwoorden (Bijv. blinden ipv blinde mensen)\n",
    "- Stigmatiseren (Bijv. dat was een beetje autistisch)\n",
    "- Incorrect gebruik van terminologie (Bijv. downies ipv mensen met het syndroom van Down)\n",
    "\n",
    "5. Leeftijd\n",
    "- Gebruik van \"bejaarden\" of \"oudjes\" in plaats van \"ouderen\" of 60-plussers\n",
    "- Inconsistencie van leeftijd (Bijv. alleen leeftijd van de oudste vermelden)\n",
    "\n",
    "6. Opleiding\n",
    "- HiÃ«rarchie tussen mensen van verschillende opleidingsrichtingen (Bijv. laagopgeleid ipv mbo-, hbo- of wo-opgeleid of praktisch en theoretisch opgeleid) \n",
    "- Onderscheid maken tussen studenten/scholieren/leerlingen. Mbo, hbo en wo vallen allemaal onder de noemer student\n",
    "\n",
    "7. Overig\n",
    "- Als een paragraaf duidelijk niet-inclusief taalgebruik bevat maar het niet onder bovenstaande categorien behoort, label het ook als niet-inclusief.\n",
    "\n",
    "Beoordeel de tekst systematisch per categorie: Gender, Seksuele oriÃ«ntatie, Etniciteit, Fysieke/Mentale beperking, Leeftijd, Opleiding, Overig. Gebruik de criteria als checklist. Je krijgt 5 paragrafen tegelijk te zien. Je reactie bevat voor al die paragrafen een classificatie van welke van de 7 categorieÃ«n er sprake is. Geef naast de categorie ook een reden voor de classificatie zodat een schrijver begrijpt hoe je tot die conclusie bent gekomen. De paragraaf die beoordeeld moet worden staat tussen <start-of-text> en <end-of-text>. \n",
    "\n",
    "Stappen:\n",
    "1. Identificeer de relevante woorden/zinnen in de paragraaf\n",
    "2. Classificeer of deze niet-inclusief zijn\n",
    "3. Leg uit waarom.\n",
    "4. Double-check de categorie en reden\n",
    "5. Zorg voor een consistente en nauwkeurige JSON-output zoals die als voorbeeld is gegeven. \n",
    "6. Check nogmaals of er een vrouwelijke vorm van beroepsnamen voorkomt in de tekst, zo ja: label deze als niet-inclusief gebruik van gender.\n",
    "\n",
    "Een output is succesvol als het taalgebruik correct is geclassificeerd volgens de opgegeven definities, met duidelijke uitleg en een antwoord in correct JSON-formaat.\n",
    "\n",
    "Voorbeeld:\n",
    "\n",
    "1. <start-of-text> {etniciteit1} <end-of-text>\n",
    "2. <start-of-text> {beperiking1} <end-of-text>\n",
    "3. <start-of-text> {seksuele_orientatie1} <end-of-text>\n",
    "4. <start-of-text> {gender1} <end-of-text>\n",
    "5. <start-of-text> {inclusief1} <end-of-text>\n",
    "\n",
    "Output:\n",
    "\n",
    "{{1: {{\"Gender\": \"0\", \"Seksuele orientatie\": \"0\", \"Etniciteit & culturele achtergrond\": \"1\", \"Fysieke/mentale beperking\": \"0\", \"Leeftijd\": \"0\", \"Opleiding\": \"0\", \"Overig\": \"0\", \"REDEN\": \"...\"}},\n",
    "2: {{\"Gender\": \"0\", \"Seksuele orientatie\": \"0\", \"Etniciteit & culturele achtergrond\": \"0\", \"Fysieke/mentale beperking\": \"1\", \"Leeftijd\": \"0\", \"Opleiding\": \"0\", \"Overig\": \"0\", \"REDEN\": \"...\"}},\n",
    "3: {{\"Gender\": \"0\", \"Seksuele orientatie\": \"1\", \"Etniciteit & culturele achtergrond\": \"0\", \"Fysieke/mentale beperking\": \"0\", \"Leeftijd\": \"0\", \"Opleiding\": \"0\", \"Overig\": \"0\", \"REDEN\": \"...\"}},\n",
    "4: {{\"Gender\": \"1\", \"Seksuele orientatie\": \"0\", \"Etniciteit & culturele achtergrond\": \"0\", \"Fysieke/mentale beperking\": \"0\", \"Leeftijd\": \"0\", \"Opleiding\": \"0\", \"Overig\": \"0\", \"REDEN\": \"...\"}},\n",
    "5: {{\"Gender\": \"0\", \"Seksuele orientatie\": \"0\", \"Etniciteit & culturele achtergrond\": \"0\", \"Fysieke/mentale beperking\": \"0\", \"Leeftijd\": \"0\", \"Opleiding\": \"0\", \"Overig\": \"0\", \"REDEN\": \"Geen sprake van niet-inclusief taalgebruik\"}}}}\n",
    "\n",
    "----------------------------------------------------------------------------------\n",
    "\n",
    "Bedankt voor het helpen bij het zorgen voor een inclusieve omgeving!\n",
    "\"\"\"\n",
    "    return [{\"role\": \"system\", \"content\": initial_prompt}]\n",
    "\n",
    "def append_paragraph(messages, paragraphs):\n",
    "  \"\"\"\n",
    "  Appends five to-be-labeled datapoints to the prompt.\n",
    "  \"\"\"\n",
    "  messages[0]['content'] += (f\"\"\"1. <start-of-text> {paragraphs[0]} <end-of-text>\n",
    "                   \n",
    "                   2. <start-of-text> {paragraphs[1]} <end-of-text>\n",
    "                   \n",
    "                   3. <start-of-text> {paragraphs[2]} <end-of-text>\n",
    "                   \n",
    "                   4. <start-of-text> {paragraphs[3]} <end-of-text>\n",
    "                   \n",
    "                   5. <start-of-text> {paragraphs[4]} <end-of-text>\"\"\")\n",
    "  return messages\n",
    "\n",
    "def rate_paragraph(paragraphs):\n",
    "  \"\"\"\n",
    "  This function calls to the OpenAI API to label the given data points. If the result is not able to be converted to a data structure, it returns None.\n",
    "  \"\"\"\n",
    "  prompts = append_paragraph(get_initial_prompt_general(), paragraphs)[0]\n",
    "  response = openai.chat.completions.create(\n",
    "                                        model=\"gpt-4o\",\n",
    "                                        messages=[\n",
    "                                          {\n",
    "                                            \"role\": prompts['role'],\n",
    "                                            \"content\": prompts['content'],\n",
    "                                            \"type\": \"json\"\n",
    "                                          }\n",
    "                                        ],\n",
    "                                        temperature=0.5 # 1\n",
    "                                        )\n",
    "  try: \n",
    "    score_dict = ast.literal_eval(response.choices[0].message.content)\n",
    "    return score_dict\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      score_dict = ast.literal_eval(response.choices[0].message.content.strip(\"`json\"))\n",
    "      return score_dict\n",
    "    except:\n",
    "      print(e)\n",
    "      return None\n",
    "\n",
    "def label_sample(to_label, int_id):\n",
    "  \"\"\"\n",
    "  This function loops through all the data points and calls the OpenAI API to label them in batches of five. If a None is returned it tries again up to five times. If it still fails, it sets all values to None sets the amount of nones to five. It also prints the progress every batch of 200.\n",
    "  \"\"\"\n",
    "  nones = 0\n",
    "  dfs = []\n",
    "  shape = to_label.shape[0]\n",
    "  for i in range(0,shape,5):\n",
    "    if i%200 == 0:\n",
    "        print(f\"{str(i)} of {str(shape)} done, of which {str(nones)} nones\")\n",
    "    sample = to_label.iloc[i:min(i+5, shape)].copy()\n",
    "    for j in range(5):\n",
    "      try:\n",
    "        output = rate_paragraph(sample['paragraphs'].values)\n",
    "        result_df = pd.DataFrame.from_dict(output, orient='index')\n",
    "        sample[f'Gender{str(int_id)}'] = result_df['Gender'].values\n",
    "        sample[f'Seksuele orientatie{str(int_id)}'] = result_df['Seksuele orientatie'].values\n",
    "        sample[f'Etniciteit & culturele achtergrond{str(int_id)}'] = result_df['Etniciteit & culturele achtergrond'].values\n",
    "        sample[f'Fysieke/mentale beperking{str(int_id)}'] = result_df['Fysieke/mentale beperking'].values\n",
    "        sample[f'Leeftijd{str(int_id)}'] = result_df['Leeftijd'].values\n",
    "        sample[f'Opleiding{str(int_id)}'] = result_df['Opleiding'].values\n",
    "        sample[f'Overig{str(int_id)}'] = result_df['Overig'].values\n",
    "        sample[f'REDEN{str(int_id)}'] = result_df['REDEN'].values\n",
    "        break\n",
    "      except Exception as e:\n",
    "        output = None\n",
    "        sample[f'Gender{str(int_id)}'] = None\n",
    "        sample[f'Seksuele orientatie{str(int_id)}'] = None\n",
    "        sample[f'Etniciteit & culturele achtergrond{str(int_id)}'] = None\n",
    "        sample[f'Fysieke/mentale beperking{str(int_id)}'] = None\n",
    "        sample[f'Leeftijd{str(int_id)}'] = None\n",
    "        sample[f'Opleiding{str(int_id)}'] = None\n",
    "        sample[f'Overig{str(int_id)}'] = None\n",
    "        sample[f'REDEN{str(int_id)}'] = None\n",
    "    if output == None:\n",
    "      nones += 5\n",
    "    dfs += [sample]\n",
    "  to_label = pd.concat(dfs)\n",
    "  print(f\"{str(shape)} done, of which {str(nones)} nones\")\n",
    "  return to_label\n",
    "\n",
    "initialize_openai_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27e26127-2e74-4df4-b2f5-6a9276444162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def label_and_save(index):\n",
    "  \"\"\"\n",
    "  To simulate multiple annotators, all samples will be labeled three times. Then the function will check if the file already exists. If it does, it will return a message that the file already exists. If it doesn't, it will label the data and save it in csv format with the defined filename.\n",
    "  \"\"\"\n",
    "  fname = \"\"\n",
    "  if not os.path.isfile(fname):\n",
    "    to_label = data\n",
    "    to_label = label_sample(to_label, 1)\n",
    "    to_label = label_sample(to_label, 2)\n",
    "    to_label = label_sample(to_label, 3)\n",
    "    to_label.to_csv(fname,sep=';')\n",
    "    return f\"{str(index)} successfull\"\n",
    "  else:\n",
    "    return f\"{str(index)} existed already\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "733beff1-4ec3-4336-b30b-b365109aaa4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "label_and_save(1)\n",
    "print(\"-\"*75)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a70799ea-c62b-4a5f-9bf5-e8d96740f544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filename_gpt_data = \"\"\n",
    "gpt_data = pd.read_csv(filename_gpt_data, delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12b651d9-e0e5-455c-9627-05034e0bf6d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpt_data['INCLUSIEF'] = (\n",
    "    (gpt_data['Gender1'] == 0) & (gpt_data['Gender2'] == 0) & (gpt_data['Gender3'] == 0) &\n",
    "    (gpt_data['Seksuele orientatie1'] == 0) & (gpt_data['Seksuele orientatie2'] == 0) & (gpt_data['Seksuele orientatie3'] == 0) &\n",
    "    (gpt_data['Etniciteit & culturele achtergrond1'] == 0) & (gpt_data['Etniciteit & culturele achtergrond2'] == 0) & (gpt_data['Etniciteit & culturele achtergrond3'] == 0) &\n",
    "    (gpt_data['Fysieke/mentale beperking1'] == 0) & (gpt_data['Fysieke/mentale beperking2'] == 0) & (gpt_data['Fysieke/mentale beperking3'] == 0) &\n",
    "    (gpt_data['Leeftijd1'] == 0) & (gpt_data['Leeftijd2'] == 0) & (gpt_data['Leeftijd3'] == 0) &\n",
    "    (gpt_data['Opleiding1'] == 0) & (gpt_data['Opleiding2'] == 0) & (gpt_data['Opleiding3'] == 0) &\n",
    "    (gpt_data['Overig1'] == 0) & (gpt_data['Overig2'] == 0) & (gpt_data['Overig3'] == 0)\n",
    ")\n",
    "\n",
    "gpt_data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f4385e7-a198-4f59-8936-f0958b801fed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(len(annotation_data))\n",
    "len(annotation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af80e1d-cbd7-482b-9d6d-05b4b4e21512",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "gpt_data = gpt_data[gpt_data['global_key'].isin(annotation_df['Global Key'])]\n",
    "\n",
    "aqua_to_red = LinearSegmentedColormap.from_list(\"AquaToRed\", [\"#42625c\", \"#a1cec5\"])\n",
    "cm = confusion_matrix(annotation_df['INCLUSIEF'], gpt_data['INCLUSIEF'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=aqua_to_red, text_kw={'color': 'white'})\n",
    "plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "plt.grid(False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Inclusive Language Model for GitHub",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}